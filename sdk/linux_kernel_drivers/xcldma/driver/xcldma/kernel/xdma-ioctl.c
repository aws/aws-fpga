/**
 *  Copyright (C) 2015-2016 Xilinx, Inc. All rights reserved.
 *  Author: Sonal Santan
 *
 *  This program is free software; you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation; either version 2 of the License, or
 *  (at your option) any later version.
 *
 *  This program is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *  GNU General Public License for more details.
 */

#include <linux/module.h>
#include <linux/cdev.h>
#include <linux/delay.h>
#include <linux/uaccess.h>
#include <linux/fs.h>
#include <linux/io.h>
#include <linux/kernel.h>
#include <linux/firmware.h>
#include <linux/pci.h>
#include <linux/vmalloc.h>


#include "xdma-core.h"
#include "xbar_sys_parameters.h"

#define MULTFRAC_BUG      1
#define MAX_FREQ_IN_MHZ   500
#define FREQ_TABLE_SIZE   (MAX_FREQ_IN_MHZ/10)
// Sysmon related define
#define SYSMON_BASEADDRESS 	0xA0000 	// SYSMON IP BASE ADDRESS
#define SYSMON_TEMP 		0x400 		// TEMPOERATURE REGISTER ADDRESS
#define SYSMON_VCCINT		0x404 		// VCCINT REGISTER OFFSET
#define SYSMON_VCCAUX		0x408 		// VCCAUX REGISTER OFFSET
#define SYSMON_VCCBRAM		0x418 		// VCCBRAM REGISTER OFFSET

/*
 * Precomputed table with config0 and config2 register values together with
 * target frequency. The steps are 10 MHz apart. Table generated by wiz.pl
 */

const static struct xdma_ocl_clockwiz frequency_table[] = {
	{/* 600*/   60, 0x0601, 0x000a},
	{/* 600*/   66, 0x0601, 0x0009},
	{/* 600*/   75, 0x0601, 0x0008},
	{/* 800*/   80, 0x0801, 0x000a},
	{/* 600*/   85, 0x0601, 0x0007},
	{/* 900*/   90, 0x0901, 0x000a},
	{/*1000*/  100, 0x0a01, 0x000a},
	{/*1100*/  110, 0x0b01, 0x000a},
	{/* 700*/  116, 0x0701, 0x0006},
	{/*1100*/  122, 0x0b01, 0x0009},
	{/* 900*/  128, 0x0901, 0x0007},
	{/*1200*/  133, 0x0c01, 0x0009},
	{/*1400*/  140, 0x0e01, 0x000a},
	{/*1200*/  150, 0x0c01, 0x0008},
	{/*1400*/  155, 0x0e01, 0x0009},
	{/* 800*/  160, 0x0801, 0x0005},
	{/*1000*/  166, 0x0a01, 0x0006},
	{/*1200*/  171, 0x0c01, 0x0007},
	{/* 900*/  180, 0x0901, 0x0005},
	{/*1300*/  185, 0x0d01, 0x0007},
	{/*1400*/  200, 0x0e01, 0x0007},
	{/*1300*/  216, 0x0d01, 0x0006},
	{/* 900*/  225, 0x0901, 0x0004},
	{/*1400*/  233, 0x0e01, 0x0006},
	{/*1200*/  240, 0x0c01, 0x0005},
	{/*1000*/  250, 0x0a01, 0x0004},
	{/*1300*/  260, 0x0d01, 0x0005},
	{/* 800*/  266, 0x0801, 0x0003},
	{/*1100*/  275, 0x0b01, 0x0004},
	{/*1400*/  280, 0x0e01, 0x0005},
	{/*1200*/  300, 0x0c01, 0x0004},
	{/*1300*/  325, 0x0d01, 0x0004},
	{/*1000*/  333, 0x0a01, 0x0003},
	{/*1400*/  350, 0x0e01, 0x0004},
	{/*1100*/  366, 0x0b01, 0x0003},
	{/*1200*/  400, 0x0c01, 0x0003},
	{/*1300*/  433, 0x0d01, 0x0003},
	{/* 900*/  450, 0x0901, 0x0002},
	{/*1400*/  466, 0x0e01, 0x0003},
	{/*1000*/  500, 0x0a01, 0x0002}
};

static unsigned find_matching_freq_config(unsigned freq)
{
	unsigned start = 0;
	unsigned end = ARRAY_SIZE(frequency_table) - 1;
	unsigned idx = ARRAY_SIZE(frequency_table) - 1;
	if (freq < frequency_table[0].ocl)
		return 0;
	if (freq > frequency_table[ARRAY_SIZE(frequency_table) - 1].ocl)
		return ARRAY_SIZE(frequency_table) - 1;

	while (start < end) {
		printk(KERN_DEBUG "Idx %d Target %d Table %d\n", idx, freq, frequency_table[idx].ocl);
		if (freq == frequency_table[idx].ocl)
			break;
		if (freq < frequency_table[idx].ocl) {
			end = idx;
		}
		else {
			start = idx + 1;
		}
		idx = start + (end - start)/2;
	}
	if (freq < frequency_table[idx].ocl)
		idx--;
	printk(KERN_DEBUG "Matched Idx %d Target %d Table %d\n", idx, freq, frequency_table[idx].ocl);
	return idx;
}

const static unsigned clock_baseaddr[OCL_NUM_CLOCKS] = {
	OCL_CLKWIZ_BASEADDR,
	OCL_CLKWIZ_BASEADDR2
};

// Temperature in C  =   ADC  501.3743
//                     -----------------  273.6777
//                          2^bits
// Max delta with this approximation found to be ~  1.3172 C
static inline int16_t onchip_temp(uint32_t temp)
{
	s64 t = (temp * 50138);
	t = t >> 16;
	t = t / 100;
	t = t - 274;
	printk(KERN_DEBUG "temp : %x: Celsius: %lld \n", temp, t);
	return t;

}

static inline unsigned short to_volt(uint32_t volt)
{
	unsigned short volts = ((volt * 1000 * 3) >> 16) ;
	printk(KERN_DEBUG "volt : %u: Volts: %u mV\n", volt, volts);
	return volts;
}

static int reinit(struct xdma_dev *lro)
{
	int rc = 0;
	int dir_from_dev;
	int channel;
	struct xdma_engine *engine = NULL;

	/* Renable the interrupts */
	rc = interrupts_enable(lro, XDMA_OFS_INT_CTRL, 0x00ffffffUL);
	for (dir_from_dev = 0; dir_from_dev < 2; dir_from_dev++) {
		/* Re-init all the channels */
		for (channel = 0; channel < XDMA_CHANNEL_NUM_MAX; channel++) {
			engine = lro->engine[channel][dir_from_dev];
			if (engine)
				engine_reinit(engine);
		}
	}
	return rc;
}


static unsigned compute_unit_busy(struct xdma_dev *lro)
{
	int i = 0;
	unsigned result = 0;
	u32 r = ioread32(lro->bar[USER_BAR] + AXI_GATE_OFFSET_READ);

	/* r != 0x3 implies that OCL region is isolated and we cannot read CUs' status */
	if (r != 0x3)
		return 0;

	for (i = 0; i < 16; i++) {
		r = ioread32(lro->bar[USER_BAR] + OCL_CTLR_OFFSET + i * OCL_CU_CTRL_RANGE);
		if (r == 0x1)
			result |= (r << i);
	}
	return result;
}


void freezeAXIGate(struct xdma_dev *lro)
{
	u8 w = 0x0;
	u32 t;

	BUG_ON(lro->axi_gate_frozen);
//	printk(KERN_DEBUG "IOCTL %s:%d\n", __FILE__, __LINE__);
	t = ioread32(lro->bar[USER_BAR] + AXI_GATE_OFFSET_READ);
//	printk("Register %x\n", t);
	iowrite8(w, lro->bar[USER_BAR] + AXI_GATE_OFFSET);
	t = ioread32(lro->bar[USER_BAR] + AXI_GATE_OFFSET_READ);
//	printk("Register %x\n", t);
	lro->axi_gate_frozen = 1;
	printk(KERN_DEBUG "%s: Froze AXI gate\n", DRV_NAME);
}

void freeAXIGate(struct xdma_dev *lro)
{
	/*
	 * First pulse the OCL RESET. This is important for PR with multiple
	 * clocks as it resets the edge triggered clock converter FIFO
	 */
	u8 w = 0x2;
	u32 t;

	BUG_ON(!lro->axi_gate_frozen);
//	printk(KERN_DEBUG "IOCTL %s:%d\n", __FILE__, __LINE__);
	t = ioread32(lro->bar[USER_BAR] + AXI_GATE_OFFSET_READ);
//	printk("Register %x\n", t);
	iowrite8(w, lro->bar[USER_BAR] + AXI_GATE_OFFSET);
	ndelay(500);

	w = 0x0;
	t = ioread32(lro->bar[USER_BAR] + AXI_GATE_OFFSET_READ);
//	printk("Register %x\n", t);
	iowrite8(w, lro->bar[USER_BAR] + AXI_GATE_OFFSET);
	ndelay(500);

	w = 0x2;
	t = ioread32(lro->bar[USER_BAR] + AXI_GATE_OFFSET_READ);
//	printk("Register %x\n", t);
	iowrite8(w, lro->bar[USER_BAR] + AXI_GATE_OFFSET);
	ndelay(500);

	w = 0x3;
	t = ioread32(lro->bar[USER_BAR] + AXI_GATE_OFFSET_READ);
//	printk("Register %x\n", t);
	iowrite8(w, lro->bar[USER_BAR] + AXI_GATE_OFFSET);
	ndelay(500);
	t = ioread32(lro->bar[USER_BAR] + AXI_GATE_OFFSET_READ);
//	printk("Register %x\n", t);
	lro->axi_gate_frozen = 0;
	printk(KERN_DEBUG "%s: Un-froze AXI gate\n", DRV_NAME);
}

static unsigned get_ocl_frequency(const struct xdma_dev *lro, unsigned offset)
{
	u32 val;
	const u64 input = (lro->pci_dev->device == 0x8138) ? XDMA_KU3_INPUT_FREQ : XDMA_7V3_INPUT_FREQ;
	u32 mul0, div0;
	u32 mul_frac0 = 0;
	u32 div1;
	u32 div_frac1 = 0;
	u64 freq;

	printk(KERN_DEBUG "%s:%s offset: %x\n", DRV_NAME, __FUNCTION__, offset);
	val = ioread32(lro->bar[USER_BAR] + offset + OCL_CLKWIZ_STATUS_OFFSET);
	printk(KERN_DEBUG "%s: ClockWiz SR %x\n", DRV_NAME, val);
	if ((val & 1) == 0)
		return 0;

	val = ioread32(lro->bar[USER_BAR] + offset + OCL_CLKWIZ_CONFIG_OFFSET(0));
	printk(KERN_DEBUG "%s: ClockWiz CONFIG(0) %x\n", DRV_NAME, val);

	div0 = val & 0xff;
	mul0 = (val & 0xff00) >> 8;
	if (val & BIT(26)) {
		mul_frac0 = val >> 16;
		mul_frac0 &= 0x3ff;
	}

	/*
	 * Multiply both numerator (mul0) and the denominator (div0) with 1000 to
	 * account for fractional portion of multiplier
	 */
	mul0 *= 1000;
	mul0 += mul_frac0;
	div0 *= 1000;

	val = ioread32(lro->bar[USER_BAR] + offset + OCL_CLKWIZ_CONFIG_OFFSET(2));
	printk(KERN_DEBUG "%s: ClockWiz CONFIG(2) %x\n", DRV_NAME, val);
	div1 = val &0xff;
	if (val & BIT(18)) {
		div_frac1 = val >> 8;
		div_frac1 &= 0x3ff;
	}

	/*
	 * Multiply both numerator (mul0) and the denominator (div1) with 1000 to
	 * account for fractional portion of divider
	 */

	div1 *= 1000;
	div1 += div_frac1;
	printk(KERN_DEBUG "%s: CLKOUT0_DIVIDE_F %d\n", DRV_NAME, div1);
	printk(KERN_DEBUG "%s: CLKFBOUT_MULT_F %d\n", DRV_NAME, mul0);
	printk(KERN_DEBUG "%s: DIVCLK_DIVIDE %d\n", DRV_NAME, div0);
	div0 *= div1;
	mul0 *= 1000;
	if (div0 == 0) {
		printk(KERN_ERR "%s: ClockWiz Invalid divider 0\n", DRV_NAME);
		return 0;
	}
	freq = (input * mul0)/div0;
	printk(KERN_DEBUG "%s: ClockWiz OCL Frequency %lld\n", DRV_NAME, freq);
	return freq;

}

static int pcie_link_info(const struct xdma_dev *lro, struct xdma_ioc_info2 *obj)
{
	u16 stat;
	long result;

	obj->pcie_link_width = 0;
	obj->pcie_link_speed = 0;
	result = pcie_capability_read_word(lro->pci_dev, PCI_EXP_LNKSTA, &stat);
	if (result)
		return result;
	obj->pcie_link_width = (stat & PCI_EXP_LNKSTA_NLW) >> PCI_EXP_LNKSTA_NLW_SHIFT;
	obj->pcie_link_speed = stat & PCI_EXP_LNKSTA_CLS;
	return 0;
}

int device_info(const struct xdma_dev *lro, struct xdma_ioc_info2 *obj)
{
	unsigned i;
	u32 val;
	memset(obj, 0, sizeof(struct xdma_ioc_info2));
	obj->vendor = lro->pci_dev->vendor;
	obj->device = lro->pci_dev->device;
	obj->subsystem_vendor = lro->pci_dev->subsystem_vendor;
	obj->subsystem_device = lro->pci_dev->subsystem_device;
	obj->feature_id = lro->feature_id;
	obj->driver_version = XDMA_DRIVER_MAJOR * 1000 + XDMA_DRIVER_MINOR * 100 + XDMA_DRIVER_PATCHLEVEL;
	obj->num_clocks = 1;
	if (is_multiple_clock(lro)) {
		obj->num_clocks = OCL_NUM_CLOCKS;
		for(i = 0; i < OCL_NUM_CLOCKS; ++i) {
			obj->ocl_frequency[i] = get_ocl_frequency(lro, clock_baseaddr[i]);
		}
	}
	else {
		obj->ocl_frequency[0] = get_ocl_frequency(lro, OCL_CLKWIZ_BASEADDR);
	}

	val = ioread32(lro->bar[USER_BAR] + GENERAL_STATUS);
	obj->mig_calibration = (val & BIT(0)) ? true : false;

	if (is_sysmon_supported(lro)) {
		printk(KERN_DEBUG "%s: Sysmon supported. \n", DRV_NAME);
		// From Sysmon
		val = ioread32(lro->bar[USER_BAR] + SYSMON_BASEADDRESS + SYSMON_TEMP);
		obj->onchip_temp = onchip_temp(val);
		val = ioread32(lro->bar[USER_BAR] + SYSMON_BASEADDRESS + SYSMON_VCCINT);
		obj->vcc_int = to_volt(val);
		val = ioread32(lro->bar[USER_BAR] + SYSMON_BASEADDRESS + SYSMON_VCCAUX);
		obj->vcc_aux= to_volt(val);
		val = ioread32(lro->bar[USER_BAR] + SYSMON_BASEADDRESS + SYSMON_VCCBRAM);
		obj->vcc_bram= to_volt(val);
	}
	else {
		printk(KERN_DEBUG "%s: Sysmon not supported. \n", DRV_NAME);
		obj->onchip_temp = 0;
		obj->vcc_int = 0;
		obj->vcc_aux = 0;
		obj->vcc_bram = 0;
	}

	// TODO: Fill in the right values.
	obj->fan_temp	= 0;
	obj->fan_speed	= 0;

	return pcie_link_info(lro, obj);
}

static long version_ioctl(struct xdma_char *lro_char, void __user *arg)
{
	struct xdma_ioc_info obj;
	struct xdma_ioc_info2 obj2;
	struct xdma_dev *lro = lro_char->lro;
	int err = device_info(lro, &obj2);
	convert_to_info(&obj2, &obj);
	if (copy_to_user(arg, &obj, sizeof(struct xdma_ioc_info)))
		return -EFAULT;
	return err;
}

static long version2_ioctl(struct xdma_char *lro_char, void __user *arg)
{
	struct xdma_ioc_info2 obj;
	struct xdma_dev *lro = lro_char->lro;
	int err = device_info(lro, &obj);
	if (copy_to_user(arg, &obj, sizeof(struct xdma_ioc_info2)))
		return -EFAULT;
	return err;
}

static long reset_ocl_ioctl(struct xdma_char *lro_char)
{
	struct xdma_dev *lro = lro_char->lro;

	/* If compute units are not busy then nothing to do */
	if (!compute_unit_busy(lro))
		return 0;

	freezeAXIGate(lro);
	freeAXIGate(lro);
	return compute_unit_busy(lro) ? -EBUSY : 0;
}

/**
 * @returns: NULL if aer capability is not found walking up to the root port
 *         : pci_dev ptr to the port which is aer capable.
 */
static struct pci_dev * find_aer_cap(struct pci_dev *bridge)
{
	struct pci_dev *prev_bridge = bridge;
	int cap;

	if (bridge == NULL)
		return NULL;
	/*
	 * Walk the hierarchy up to the root port
	 **/
	do {
		printk(KERN_DEBUG "%s: inside do while loop..find_aer_cap \n", DRV_NAME);
		cap = pci_find_ext_capability(bridge, PCI_EXT_CAP_ID_ERR);
		if (cap) {
			printk(KERN_DEBUG "%s: AER capability found. \n", DRV_NAME);
			return bridge;
		}

		prev_bridge = bridge;
		bridge = bridge->bus->self;

		if (!bridge || prev_bridge == bridge) {
			printk(KERN_DEBUG "%s: AER capability not found. Ignoring boot command. \n", DRV_NAME);
			return NULL;
		}

	} while (pci_pcie_type(bridge) != PCI_EXP_TYPE_ROOT_PORT);

	return NULL;
}

/*
 * pcie_(un)mask_surprise_down inspired by myri10ge driver, myri10ge.c
 */
static int pcie_mask_surprise_down(struct pci_dev *pdev, u32 *orig_mask)
{
	struct pci_dev *bridge = pdev->bus->self;
	int cap;
	u32 mask;

	printk(KERN_DEBUG "%s: pcie_mask_surprise_down \n", DRV_NAME);

	bridge = find_aer_cap(bridge);
	if(bridge) {
		cap = pci_find_ext_capability(bridge, PCI_EXT_CAP_ID_ERR);
		if (cap) {
			pci_read_config_dword(bridge, cap + PCI_ERR_UNCOR_MASK, orig_mask);
			mask = *orig_mask;
			mask |= 0x20;
			pci_write_config_dword(bridge, cap + PCI_ERR_UNCOR_MASK, mask);
			return 0;
		}
	}

	return -ENOSYS;
}

static int pcie_unmask_surprise_down(struct pci_dev *pdev, u32 orig_mask)
{
	struct pci_dev *bridge = pdev->bus->self;
	int cap;

	printk(KERN_DEBUG "%s: pcie_unmask_surprise_down \n", DRV_NAME);

	bridge = find_aer_cap(bridge);
	if(bridge) {
		cap = pci_find_ext_capability(bridge, PCI_EXT_CAP_ID_ERR);
		if (cap) {
			pci_write_config_dword(bridge, cap + PCI_ERR_UNCOR_MASK, orig_mask);
			return 0;
		}
	}

	return -ENOSYS;
}

/*
 * Inspired by GenWQE driver, card_base.c
 */
static int pci_fundamental_reset(struct xdma_dev *lro)
{
	int rc;
	u32 orig_mask;
	struct pci_dev *pci_dev = lro->pci_dev;

	/*
	 * lock pci config space access from userspace,
	 * save state and issue PCIe fundamental reset
	 */
	pci_cfg_access_lock(pci_dev);
	pci_save_state(pci_dev);
	rc = pcie_mask_surprise_down(pci_dev, &orig_mask);
	if (rc)
		goto done;

#if defined(__PPC64__)
	/*
	 * On PPC64LE use pcie_warm_reset which will cause the FPGA to
	 * reload from PROM
	 */
	rc = pci_set_pcie_reset_state(pci_dev, pcie_warm_reset);
	if (rc)
		goto done;
	/* keep PCIe reset asserted for 250ms */
	msleep(250);
	rc = pci_set_pcie_reset_state(pci_dev, pcie_deassert_reset);
	if (rc)
		goto done;
	/* Wait for 2s to reload flash and train the link */
	msleep(2000);
#else
	/*
	 * On x86_64 use special bitstream sequence which forces the FPGA to
	 * reload from PROM
	 */
	rc = load_reset_mini_bitstream(lro);
	if (rc)
		goto done;
#endif
done:
	pci_restore_state(pci_dev);
	rc = pcie_unmask_surprise_down(pci_dev, orig_mask);
	pci_cfg_access_unlock(pci_dev);
	if (!rc)
		rc = reinit(lro);
	return rc;
}


/**
 * Simple implementation of device reset using PCIe hot reset
 * Toggle a special bit in the PCI_MIN_GNT config byte of connected
 * root port to reset the card except for the EP which stays up.
 * There is no support yet for quashing any pending DMA transactions,
 * and returning EIO for pending DMA read/writes, etc. More features
 * will be added incrementally. Note this does not reset the PCIe link.
 */

static long reset_hot_ioctl(struct xdma_char *lro_char)
{
	u32 *pci_cfg = NULL;
	u32 pci_cfg2[0x40];
	u8 hot;
	int i;
	long err = 0;
	const char *ep_name;
	const char *rp_name;
	struct xdma_dev *lro = lro_char->lro;
	struct pci_dev *pdev = lro->pci_dev;

	BUG_ON(!pdev->bus);
	BUG_ON(!pdev->bus->self);

	if (!pdev->bus || !pdev->bus->self) {
		printk(KERN_ERR "%s: Unable to identify device root port for card %d\n", DRV_NAME,
		       lro->instance);
		err = -EIO;
		goto done;
	}

	ep_name = pdev->bus->name;
#if defined(__PPC64__)
	printk(KERN_INFO "%s: Ignoring reset operation for card %d in slot %s:%02x:%1x\n", DRV_NAME, lro->instance, ep_name,
	       PCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn));
#else
	printk(KERN_INFO "%s: Trying to reset card %d in slot %s:%02x:%1x\n", DRV_NAME, lro->instance, ep_name,
	       PCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn));

	/* Allocate buffer for 256B PCIe config space */
	pci_cfg = kmalloc(0x100, GFP_KERNEL);
	if (!pci_cfg)
		return -ENOMEM;

	rp_name = pdev->bus->parent ? pdev->bus->parent->name : "null";
	/* Save the card's PCIe config space */

	for (i = 0; i < 0x100; i += 4) {
		pci_read_config_dword(pdev, i, &pci_cfg[i/4]);
	}

	pci_read_config_byte(pdev->bus->self, PCI_MIN_GNT, &hot);

	/* Toggle the PCIe hot reset bit in the root port */
	pci_write_config_byte(pdev->bus->self, PCI_MIN_GNT, hot | 0x40);

	ssleep(1);

	pci_write_config_byte(pdev->bus->self, PCI_MIN_GNT, hot);

	ssleep(1);

	/* Restore the card's PCIe config space */
	for (i = 0; i < 0x100; i += 4)
		pci_write_config_dword(pdev, i, pci_cfg[i/4]);

	ssleep(1);

	/* Verify we were able to restore card's PCIe config space */
	for (i = 0; i < 0x100; i += 4) {
		pci_read_config_dword(pdev, i, &pci_cfg2[i/4]);
		if (pci_cfg2[i/4] != pci_cfg[i/4])
			printk(KERN_WARNING "%s: Unable to restore config dword at %x (%x->%x) for card %d in slot %s:%02x:%1x\n",
			       DRV_NAME, i, pci_cfg[i/4], pci_cfg2[i/4], lro->instance, ep_name, PCI_SLOT(pdev->devfn),
			       PCI_FUNC(pdev->devfn));
	}

	err = reinit(lro);
	ssleep(1);
#endif
done:
	kfree(pci_cfg);
	return err;
}

/*
 * Based on Clocking Wizard v5.1, section Dynamic Reconfiguration through AXI4-Lite
 */
long ocl_freqscaling2(struct xdma_dev *lro, bool force)
{
	int i = 0;
	int j = 0;
	u32 val = 0;
	unsigned curr_freq;
	unsigned idx = 0;
	long err = 0;
	/* Divide by 1; multiply by 5 for Utrascale and 10 for V7 */
	u32 config = (lro->pci_dev->device == 0x8138) ? XDMA_KU3_CLKWIZ_CONFIG0 : XDMA_7V3_CLKWIZ_CONFIG0;

	for(i = 0; i < OCL_NUM_CLOCKS; ++i) {
		// A value of zero means skip scaling for this clock index
		if (!lro->ocl_frequency[i])
			continue;

		idx = find_matching_freq_config(lro->ocl_frequency[i]);
		curr_freq = get_ocl_frequency(lro, clock_baseaddr[i]);

		/* If current frequency is in the same step as the requested frequency then nothing to do */
		if (!force && (find_matching_freq_config(curr_freq) == idx))
			continue;

		val = ioread32(lro->bar[USER_BAR] + clock_baseaddr[i] + OCL_CLKWIZ_STATUS_OFFSET);
		if (val != 1) {
			printk(KERN_DEBUG "%s: ClockWiz BUSY %x\n", DRV_NAME, val);
			err = -EBUSY;
			break;;
		}

		config = frequency_table[idx].config0;
		iowrite32(config, lro->bar[USER_BAR] + clock_baseaddr[i] + OCL_CLKWIZ_CONFIG_OFFSET(0));
		config = frequency_table[idx].config2;
		iowrite32(config, lro->bar[USER_BAR] + clock_baseaddr[i] + OCL_CLKWIZ_CONFIG_OFFSET(2));
		msleep(10);
		iowrite32(0x00000007, lro->bar[USER_BAR] + clock_baseaddr[i] + OCL_CLKWIZ_CONFIG_OFFSET(23));
		msleep(1);
		iowrite32(0x00000002, lro->bar[USER_BAR] + clock_baseaddr[i] + OCL_CLKWIZ_CONFIG_OFFSET(23));
		printk(KERN_DEBUG "%s: ClockWiz waiting for locked signal\n", DRV_NAME);
		msleep(100);
		for (j = 0; j < 100; j++) {
			val = ioread32(lro->bar[USER_BAR] + clock_baseaddr[i] + OCL_CLKWIZ_STATUS_OFFSET);
			if (val != 1) {
				msleep(100);
				continue;
			}
		}
		if (val != 1) {
			printk(KERN_ERR "%s: ClockWiz MMCM/PLL did not lock after %d ms, restoring the original configuration\n", DRV_NAME, 100 * 100);
			/* restore the original clock configuration */
			iowrite32(0x00000004, lro->bar[USER_BAR] + clock_baseaddr[i] + OCL_CLKWIZ_CONFIG_OFFSET(23));
			msleep(10);
			iowrite32(0x00000000, lro->bar[USER_BAR] + clock_baseaddr[i] + OCL_CLKWIZ_CONFIG_OFFSET(23));
			err = -ETIMEDOUT;
			break;
		}
		val = ioread32(lro->bar[USER_BAR] + clock_baseaddr[i] + OCL_CLKWIZ_CONFIG_OFFSET(0));
		printk(KERN_DEBUG "%s: ClockWiz CONFIG(0) %x\n", DRV_NAME, val);
		val = ioread32(lro->bar[USER_BAR] + clock_baseaddr[i] + OCL_CLKWIZ_CONFIG_OFFSET(2));
		printk(KERN_DEBUG "%s: ClockWiz CONFIG(2) %x\n", DRV_NAME, val);
	}
	return err;
}

static long  ocl_freqscaling2_ioctl(struct xdma_char *lro_char, void __user *arg)
{
	struct xdma_ioc_freqscaling2 freq_obj;
	struct xdma_dev *lro = lro_char->lro;
	int i = 0;
	u32 val = 0;
	long err = 0;

	if (copy_from_user((void *)&freq_obj, arg, sizeof(struct xdma_ioc_freqscaling2)))
		return -EFAULT;

	for(i = 0; i < OCL_NUM_CLOCKS; ++i) {
		if (!freq_obj.ocl_target_freq[i])
			continue;
		val = ioread32(lro->bar[USER_BAR] + clock_baseaddr[i] + OCL_CLKWIZ_STATUS_OFFSET);
		if ((val & 0x1) == 0)
			return -EBUSY;
	}

	if (compute_unit_busy(lro))
		return -EBUSY;

	memcpy(lro->ocl_frequency, freq_obj.ocl_target_freq, sizeof(freq_obj.ocl_target_freq));
	/*
	 * TODO:
	 * Need to lock the device so that another thread is not fiddling with the device at
	 * the same time, like downloading bitstream or starting kernel, etc.
	 */
	freezeAXIGate(lro);
	err = ocl_freqscaling2(lro, false);
	freeAXIGate(lro);
	return err;
}


static long ocl_freqscaling_ioctl(struct xdma_char *lro_char, void __user *arg)
{
	struct xdma_ioc_freqscaling obj;
	struct xdma_dev *lro = lro_char->lro;
	long err = 0;
	u32 val = 0;

	if (copy_from_user((void *)&obj, arg, sizeof(struct xdma_ioc_freqscaling)))
		return -EFAULT;

	val = ioread32(lro->bar[USER_BAR] + OCL_CLKWIZ_STATUS);
	if ((val & 0x1) == 0)
		return -EBUSY;

	if (compute_unit_busy(lro))
		return -EBUSY;

	lro->ocl_frequency[0] = obj.ocl_target_freq;

	freezeAXIGate(lro);
	err = ocl_freqscaling2(lro, false);
	freeAXIGate(lro);
	return err;
}


long char_ctrl_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
{
	struct xdma_dev *lro;
	struct xdma_char *lro_char = (struct xdma_char *)filp->private_data;
	struct xdma_ioc_base ioctl_obj;
	long result = 0;
	BUG_ON(!lro_char);
	BUG_ON(lro_char->magic != MAGIC_CHAR);
	lro = lro_char->lro;
	BUG_ON(!lro);
	BUG_ON(lro->magic != MAGIC_DEVICE);

	printk(KERN_DEBUG "IOCTL request %u\n", cmd & 0xff);

	if (lro_char != lro->user_char_dev)
		return -ENOTTY;

	if (_IOC_TYPE(cmd) != XDMA_IOC_MAGIC)
		return -ENOTTY;

	if (_IOC_DIR(cmd) & _IOC_READ)
		result = !access_ok(VERIFY_WRITE, (void __user *)arg, _IOC_SIZE(cmd));
	else if (_IOC_DIR(cmd) & _IOC_WRITE)
		result =  !access_ok(VERIFY_READ, (void __user *)arg, _IOC_SIZE(cmd));

	if (result)
		return -EFAULT;

	if (copy_from_user((void *)&ioctl_obj, (void *) arg, sizeof(struct xdma_ioc_base)))
		return -EFAULT;
	if (ioctl_obj.magic != XDMA_XCL_MAGIC)
		return -ENOTTY;

	switch (cmd) {
	case XDMA_IOCINFO:
		return version_ioctl(lro_char, (void __user *)arg);
	case XDMA_IOCINFO2:
		return version2_ioctl(lro_char, (void __user *)arg);
	case XDMA_IOCICAPDOWNLOAD:
	case XDMA_IOCMCAPDOWNLOAD:
		return bitstream_ioctl(lro_char, cmd, (void __user *)arg);
	case XDMA_IOCOCLRESET:
		return reset_ocl_ioctl(lro_char);
	case XDMA_IOCHOTRESET:
		return reset_hot_ioctl(lro_char);
	case XDMA_IOCFREQSCALING:
		return ocl_freqscaling_ioctl(lro_char, (void __user *)arg);
	case XDMA_IOCFREQSCALING2:
		return ocl_freqscaling2_ioctl(lro_char, (void __user *)arg);
	case XDMA_IOCREBOOT:
		return pci_fundamental_reset(lro_char->lro);
	default:
		return -ENOTTY;
	}
	return 0;
}


long reset_device_if_running(struct xdma_dev *lro)
{
	/* If compute units are not busy then nothing to do */
	if (!compute_unit_busy(lro))
		return 0;

	/* If one or more compute units are busy then try to reset the card */
	printk(KERN_INFO "%s: One or more compute units busy\n", DRV_NAME);

	if (reset_ocl_ioctl(lro->user_char_dev) == 0)
		return 0;
	return reset_hot_ioctl(lro->user_char_dev);
}
